{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c17e3d74-174d-4d5c-aa0a-326efb80e134",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import functools\n",
    "import types\n",
    "import os\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "from pandas import *\n",
    "from functools import *\n",
    "from pyspark import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import *\n",
    "from datetime import datetime, timedelta\n",
    "from delta.tables import *\n",
    "\n",
    "# Iniciar uma sessão Spark\n",
    "spark = SparkSession.builder.appName(\"carregando_dados\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66fc8c21-b5a7-4c20-908f-96019793a056",
     "showTitle": true,
     "title": "conexão com o mongo"
    }
   },
   "outputs": [],
   "source": [
    "# Configurações do MongoDB\n",
    "connectionString_cliente = \"mongodb+srv://antoniocastro:VwA29mJK7yNvQ1dz8e@asaplog-development-pri.2rgxp.mongodb.net/?retryWrites=true&w=majority\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b043aa44-d035-4ad7-b53f-68f17f371942",
     "showTitle": true,
     "title": "Pedidos"
    }
   },
   "outputs": [],
   "source": [
    "# database a ser carregado\n",
    "database_pedido=\"pedidoentrega\"\n",
    "\n",
    "df_pedidoentrega = spark.read.format(\"mongo\")\\\n",
    "    .option(\"database\", database_pedido)\\\n",
    "        .option(\"spark.mongodb.input.uri\", connectionString_cliente)\\\n",
    "            .option(\"collection\",\"pedidoEntrega\").load()\n",
    "\n",
    "# selecionando os campos\n",
    "df_PedidoEntrega = df_pedidoentrega.select(\n",
    "    col(\"_id.oid\").alias(\"id_pedido\"),\\\n",
    "    col(\"clienteGUid\").alias(\"codigoCliente\"),\\\n",
    "    col(\"dateCreated\").alias(\"data_criacao\"),\\\n",
    "    col(\"lastUpdated\").alias(\"ultima_atualizacao\"),\\\n",
    "    col(\"dataPlanejada\").alias(\"data_planejada\"),\\\n",
    "    col(\"dataPrevisaoEntrega\").alias(\"data_previsao_entrega\"),\\\n",
    "    col(\"prazoMaximaEntrega\").alias(\"prazo_maximo_entrega\"),\\\n",
    "    col(\"tipoEntrega\").alias(\"tipo_entrega\"),\\\n",
    "    col(\"tipoTransferencia\").alias(\"tipo_transferencia\"),\\\n",
    "    col(\"tipoOperacao\").alias(\"tipo_operacao\"),\\\n",
    "    col(\"statusPedido\").alias(\"status_pedido\"),\\\n",
    "    col(\"nfe.totalNota\").alias(\"valor_nota\"),\\\n",
    "    col(\"origem.estado\").alias(\"estado_origem\"),\\\n",
    "    col(\"destino.estado\").alias(\"destino_estado\"),\\\n",
    "    col(\"destino.cidade\").alias(\"destino_cidade\"),\\\n",
    "    col(\"destino.cep\").alias(\"destino_cep\")\n",
    ")\n",
    "\n",
    "df_PedidoEntrega = df_PedidoEntrega.filter(col(\"data_criacao\")>=\"2024-01-01\")\n",
    "\n",
    "# criando a tabela temporaria para rodar o upsert\n",
    "db_name = \"asap_mvp\"\n",
    "table_name = \"dados_pedidos\"\n",
    "\n",
    "# gravando em tabela\n",
    "df_PedidoEntrega.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(f\"{db_name}.{table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2b40f02-d1cd-46a3-a4ef-69327bfd5374",
     "showTitle": true,
     "title": "Pedidos Filhos de Roteiros"
    }
   },
   "outputs": [],
   "source": [
    "# selecionando campos com arrays\n",
    "df_PedidoEntrega = df_pedidoentrega.select(\n",
    "    col(\"_id.oid\").alias(\"id_pedido_filho\"),\\\n",
    "    col(\"dateCreated\").alias(\"data_criacao\"),\\\n",
    "    col(\"lastUpdated\").alias(\"ultima_atualizacao\"),\\\n",
    "    explode(\"codigoRoteiros\").alias(\"codigoRoteiros\")\n",
    ")\n",
    "\n",
    "df_PedidoEntrega = df_PedidoEntrega.filter(col(\"data_criacao\")>=\"2024-01-01\")\n",
    "\n",
    "# criando a tabela temporaria para rodar o upsert\n",
    "db_name = \"asap_mvp\"\n",
    "table_name = \"dados_pedidos_filhos\"\n",
    "\n",
    "# gravando em tabela\n",
    "df_PedidoEntrega.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(f\"{db_name}.{table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1089355-d6f6-451f-86c8-2b5f092301bd",
     "showTitle": true,
     "title": "Roteiros"
    }
   },
   "outputs": [],
   "source": [
    "# database a ser \n",
    "database_roteiros=\"entregas\"\n",
    "\n",
    "df_roteiros = spark.read.format(\"mongo\")\\\n",
    "    .option(\"database\", database_roteiros)\\\n",
    "        .option(\"spark.mongodb.input.uri\", connectionString_cliente)\\\n",
    "            .option(\"collection\",\"roteiro\").load()\n",
    "\n",
    "df_roteiros = df_roteiros.filter(col(\"dateCreated\")>=\"2024-01-01\")\n",
    "\n",
    "df_Roteiros = df_roteiros.select(\n",
    "    \"codigoRoteiro\",\\\n",
    "    \"date\",\\\n",
    "    \"dateCreated\",\\\n",
    "    \"lastUpdated\",\\\n",
    "    \"placaVeiculo\",\\\n",
    "    \"qtdPedidos\",\\\n",
    "    \"qtdVolumes\",\\\n",
    "    \"distanciaKm\",\\\n",
    "    \"regiaoEntregaGuid\"\n",
    ")\n",
    "\n",
    "# criando a tabela temporaria para rodar o upsert\n",
    "db_name = \"asap_mvp\"\n",
    "table_name = \"dados_roteiros\"\n",
    "\n",
    "# gravando em tabela\n",
    "df_Roteiros.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(f\"{db_name}.{table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cda6ce26-857f-42f3-b879-083961e88b60",
     "showTitle": true,
     "title": "Roteiros Pedidos filho"
    }
   },
   "outputs": [],
   "source": [
    "# filtrando os arrays de pedidos\n",
    "df_Roteiros = df_roteiros.select(\n",
    "    \"codigoRoteiro\",\\\n",
    "    \"dateCreated\",\\\n",
    "    \"lastUpdated\",\\\n",
    "    explode(\"pedidoGuidList\").alias(\"pedidGuidList\")\n",
    ")\n",
    "\n",
    "# filtrando o período de dados\n",
    "df_Roteiros = df_Roteiros.filter(col(\"dateCreated\")>=\"2024-01-01\")\n",
    "\n",
    "# criando a tabela temporaria para rodar o upsert\n",
    "db_name = \"asap_mvp\"\n",
    "table_name = \"dados_roteiros_filhos\"\n",
    "\n",
    "# gravando em tabela\n",
    "df_Roteiros.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(f\"{db_name}.{table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "293ddfea-a416-4f25-8ade-180991680ff2",
     "showTitle": true,
     "title": "Filial"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# database a ser \n",
    "database_roteiros=\"entregas\"\n",
    "\n",
    "df_filial = spark.read.format(\"mongo\")\\\n",
    "    .option(\"database\", database_roteiros)\\\n",
    "        .option(\"spark.mongodb.input.uri\", connectionString_cliente)\\\n",
    "            .option(\"collection\",\"filial\").load()\n",
    "\n",
    "df_Filial = df_filial.select(\n",
    "    col(\"_id.oid\").alias(\"id_filial\"),\\\n",
    "    \"nome\",\\\n",
    "    \"codigoFilial\",\\\n",
    "    \"nomeFantasia\",\\\n",
    ")\n",
    "\n",
    "# criando a tabela temporaria para rodar o upsert\n",
    "db_name = \"asap_mvp\"\n",
    "table_name = \"dados_filial\"\n",
    "\n",
    "# gravando em tabela\n",
    "df_Filial.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(f\"{db_name}.{table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31d54ea4-394f-4a8d-a9df-8749500c8a67",
     "showTitle": true,
     "title": "região"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# database a ser \n",
    "database_enderecos=\"endereco\"\n",
    "\n",
    "df_regiao = spark.read.format(\"mongo\")\\\n",
    "    .option(\"database\", database_enderecos)\\\n",
    "        .option(\"spark.mongodb.input.uri\", connectionString_cliente)\\\n",
    "            .option(\"collection\",\"regiaoEntrega\").load()\n",
    "\n",
    "df_Regiao = df_regiao.select(\n",
    "    col(\"_id.oid\").alias(\"id_regiao\"),\\\n",
    "    \"dateCreated\",\\\n",
    "    \"lastUpdated\",\\\n",
    "    \"codigoRegiao\",\\\n",
    "    \"filialId\",\\\n",
    "    \"nome\",\\\n",
    "    \"uf\"\n",
    ")\n",
    "\n",
    "# criando a tabela temporaria para rodar o upsert\n",
    "db_name = \"asap_mvp\"\n",
    "table_name = \"dados_regiao\"\n",
    "\n",
    "# gravando em tabela\n",
    "df_Regiao.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(f\"{db_name}.{table_name}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 224810749996341,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ingestão de dados",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
